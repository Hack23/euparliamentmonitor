---
name: ai-governance
description: AI governance for EU Parliament journalism â€” EU AI Act compliance, OWASP LLM security, bias detection, and responsible content generation
license: Apache-2.0
---

# ğŸ¤– AI Governance Skill

## Purpose

Establish governance frameworks for AI-assisted journalism in the EU Parliament Monitor. Covers EU AI Act compliance, OWASP LLM Top 10 mitigations, bias detection in parliamentary reporting, human oversight requirements, and secure integration of GitHub Copilot agents and EP MCP Server data pipelines.

## When to Use

âœ… Generating multi-language news articles with AI assistance
âœ… Configuring GitHub Copilot agent workflows (.github/agents/)
âœ… Reviewing AI-generated content for bias or hallucination
âœ… Processing EP MCP Server data through AI pipelines
âœ… Labeling AI-generated or AI-assisted content
âœ… Assessing EU AI Act obligations for the platform

âŒ General software development without AI involvement
âŒ Manual editorial decisions without AI tools
âŒ EU AI Act compliance for other organizations
âŒ AI model training or fine-tuning (not in scope)

## Core Framework

### AI Governance Decision Tree

```
AI Usage Decision:
â”‚
â”œâ”€ Is AI generating or modifying public-facing content?
â”‚   â”œâ”€ YES â†’ Apply full AI governance framework
â”‚   â”‚   â”œâ”€ Human review required before publication
â”‚   â”‚   â”œâ”€ AI involvement must be labeled
â”‚   â”‚   â”œâ”€ Bias check must be performed
â”‚   â”‚   â””â”€ Source data must be verifiable (EP MCP)
â”‚   â””â”€ NO â†’ Is AI assisting internal development?
â”‚       â”œâ”€ YES â†’ Apply development AI controls
â”‚       â”‚   â”œâ”€ Code review required (human + CodeQL)
â”‚       â”‚   â”œâ”€ Security scanning on AI-generated code
â”‚       â”‚   â””â”€ Follow Hack23 AI Policy
â”‚       â””â”€ NO â†’ Standard development practices
â”‚
â”œâ”€ EU AI Act Risk Classification
â”‚   â”œâ”€ UNACCEPTABLE â†’ Not applicable (no social scoring, etc.)
â”‚   â”œâ”€ HIGH RISK â†’ Not applicable (no biometric, hiring, etc.)
â”‚   â”œâ”€ LIMITED RISK â†’ âš ï¸ AI-generated news content
â”‚   â”‚   â”œâ”€ Transparency obligation: label AI involvement
â”‚   â”‚   â”œâ”€ Users must know content is AI-assisted
â”‚   â”‚   â””â”€ Clear disclosure in article metadata
â”‚   â””â”€ MINIMAL RISK â†’ Development tooling (Copilot, linters)
â”‚       â””â”€ No specific obligations, but follow best practices
```

### EU AI Act Compliance for News Content

```
EU AI Act â€” Limited Risk Obligations:
â”‚
â”œâ”€ Article 50: Transparency Requirements
â”‚   â”œâ”€ Disclose AI-generated content to users
â”‚   â”œâ”€ Label articles as "AI-assisted" or "AI-generated"
â”‚   â””â”€ Provide clear attribution methodology
â”‚
â”œâ”€ Implementation in EU Parliament Monitor
â”‚   â”œâ”€ HTML meta tag: <meta name="ai-generated" content="assisted">
â”‚   â”œâ”€ Visible label: "This article was generated with AI assistance"
â”‚   â”œâ”€ Footer disclosure: "Content verified against EP open data"
â”‚   â””â”€ Schema.org: "creativeWorkStatus": "AI-assisted"
â”‚
â””â”€ Exemptions
    â”œâ”€ AI used only for development tooling â†’ minimal risk
    â”œâ”€ Human-edited content with minor AI suggestions â†’ disclose
    â””â”€ Fully human-written content â†’ no AI label needed
```

### AI Content Labeling

```html
<!-- Required AI disclosure in article template -->
<article itemscope itemtype="https://schema.org/NewsArticle">
  <meta itemprop="creativeWorkStatus" content="AI-assisted">

  <!-- Visible disclosure -->
  <footer class="article-meta">
    <p class="ai-disclosure">
      ğŸ“ This article was generated with AI assistance using
      European Parliament open data. All facts are verified against
      official EP records via the
      <a href="https://github.com/Hack23/European-Parliament-MCP-Server">
        EP MCP Server</a>.
    </p>
  </footer>
</article>
```

### OWASP LLM Top 10 Mitigations

```
OWASP LLM Top 10 â€” EU Parliament Monitor Controls:
â”‚
â”œâ”€ LLM01: Prompt Injection
â”‚   â”œâ”€ Risk: Malicious input manipulates article generation
â”‚   â”œâ”€ Mitigation: EP MCP data is read-only, validated source
â”‚   â”œâ”€ Control: Input sanitization before prompt construction
â”‚   â””â”€ Status: LOW risk (no user-supplied prompts in production)
â”‚
â”œâ”€ LLM02: Insecure Output Handling
â”‚   â”œâ”€ Risk: AI output contains XSS, malformed HTML
â”‚   â”œâ”€ Mitigation: HTML sanitization on all AI output
â”‚   â”œâ”€ Control: escapeHtml() applied before rendering
â”‚   â””â”€ Status: MEDIUM risk â€” enforce output validation
â”‚
â”œâ”€ LLM03: Training Data Poisoning
â”‚   â”œâ”€ Risk: Not applicable (no model training)
â”‚   â””â”€ Status: NOT APPLICABLE
â”‚
â”œâ”€ LLM04: Model Denial of Service
â”‚   â”œâ”€ Risk: Excessive API calls to AI services
â”‚   â”œâ”€ Mitigation: Rate limiting, budget caps
â”‚   â””â”€ Status: LOW risk (batch generation, not real-time)
â”‚
â”œâ”€ LLM05: Supply Chain Vulnerabilities
â”‚   â”œâ”€ Risk: Compromised AI dependencies or models
â”‚   â”œâ”€ Mitigation: Pin dependencies, npm audit, CodeQL
â”‚   â”œâ”€ Control: SBOM generation, SLSA attestations
â”‚   â””â”€ Status: MEDIUM risk â€” monitor continuously
â”‚
â”œâ”€ LLM06: Sensitive Information Disclosure
â”‚   â”œâ”€ Risk: AI leaks internal data in generated content
â”‚   â”œâ”€ Mitigation: No secrets in prompts, data classification
â”‚   â”œâ”€ Control: Output review for PII/internal references
â”‚   â””â”€ Status: LOW risk (EP data is public)
â”‚
â”œâ”€ LLM07: Insecure Plugin Design
â”‚   â”œâ”€ Risk: MCP server integration vulnerabilities
â”‚   â”œâ”€ Mitigation: Validate all MCP responses, least privilege
â”‚   â”œâ”€ Control: Schema validation on MCP tool results
â”‚   â””â”€ Status: MEDIUM risk â€” validate MCP integration
â”‚
â”œâ”€ LLM08: Excessive Agency
â”‚   â”œâ”€ Risk: AI agents perform unauthorized actions
â”‚   â”œâ”€ Mitigation: Read-only MCP access, no write operations
â”‚   â”œâ”€ Control: Agent permissions defined in .github/agents/
â”‚   â””â”€ Status: LOW risk (static site, no server-side execution)
â”‚
â”œâ”€ LLM09: Overreliance
â”‚   â”œâ”€ Risk: Publishing AI content without verification
â”‚   â”œâ”€ Mitigation: Human review required before merge
â”‚   â”œâ”€ Control: PR review gates, editorial checklist
â”‚   â””â”€ Status: MEDIUM risk â€” enforce review workflow
â”‚
â””â”€ LLM10: Model Theft
    â”œâ”€ Risk: Not applicable (no proprietary models)
    â””â”€ Status: NOT APPLICABLE
```

### Bias Detection in EU Parliament Reporting

```javascript
/**
 * Check article content for potential bias indicators.
 * Flags disproportionate coverage or loaded language.
 *
 * @param {Object} article - Generated article content
 * @param {string} article.text - Article body text
 * @param {string[]} article.mepsmentioned - MEPs referenced
 * @param {string[]} article.groupsMentioned - Political groups referenced
 * @returns {Object} Bias assessment with flags and recommendations
 */
function assessBias(article) {
  const flags = [];

  // Check political group balance
  const groupCount = {};
  for (const group of article.groupsMentioned) {
    groupCount[group] = (groupCount[group] || 0) + 1;
  }
  const maxMentions = Math.max(...Object.values(groupCount));
  const minMentions = Math.min(...Object.values(groupCount));
  if (maxMentions > minMentions * 3) {
    flags.push({
      type: 'DISPROPORTIONATE_COVERAGE',
      detail: 'One political group mentioned 3x+ more than others',
      groups: groupCount
    });
  }

  // Check for loaded language
  const loadedTerms = [
    'radical', 'extreme', 'dangerous', 'shocking',
    'unprecedented crisis', 'power grab', 'elite'
  ];
  for (const term of loadedTerms) {
    if (article.text.toLowerCase().includes(term)) {
      flags.push({
        type: 'LOADED_LANGUAGE',
        detail: `Contains potentially loaded term: "${term}"`,
        recommendation: 'Replace with neutral factual language'
      });
    }
  }

  // Check country balance in cross-country articles
  if (article.mepsMentioned && article.mepsMentioned.length > 5) {
    const countries = new Set(article.mepsMentioned.map(m => m.country));
    if (countries.size < 3) {
      flags.push({
        type: 'GEOGRAPHIC_BIAS',
        detail: 'Article mentions MEPs from fewer than 3 countries',
        recommendation: 'Include perspectives from more member states'
      });
    }
  }

  return {
    hasBiasFlags: flags.length > 0,
    flags,
    overallRisk: flags.length === 0 ? 'LOW' : flags.length <= 2 ? 'MEDIUM' : 'HIGH'
  };
}
```

### GitHub Copilot Agent Security

```
Agent Security Controls (.github/agents/):
â”‚
â”œâ”€ Agent Inventory (8 specialized agents)
â”‚   â”œâ”€ news-journalist â€” content generation
â”‚   â”œâ”€ data-pipeline-specialist â€” MCP integration
â”‚   â”œâ”€ frontend-specialist â€” HTML/CSS/accessibility
â”‚   â”œâ”€ quality-engineer â€” testing and validation
â”‚   â”œâ”€ security-architect â€” security controls
â”‚   â”œâ”€ documentation-architect â€” documentation
â”‚   â”œâ”€ devops-engineer â€” CI/CD pipelines
â”‚   â””â”€ product-task-agent â€” issue management
â”‚
â”œâ”€ Security Principles
â”‚   â”œâ”€ Least privilege: agents access only required tools
â”‚   â”œâ”€ Separation of duties: no single agent has full control
â”‚   â”œâ”€ Audit trail: all agent actions logged via Git history
â”‚   â”œâ”€ Human gate: PR review required for all agent output
â”‚   â””â”€ No secrets: agents never handle credentials directly
â”‚
â”œâ”€ Content Generation Controls
â”‚   â”œâ”€ news-journalist: EP MCP data only (no external sources)
â”‚   â”œâ”€ Output must pass HTMLHint + axe-core validation
â”‚   â”œâ”€ Multi-language output must match source data
â”‚   â””â”€ AI disclosure label required on all generated articles
â”‚
â””â”€ MCP Integration Security
    â”œâ”€ EP MCP Server: read-only access to public EP data
    â”œâ”€ Schema validation on all MCP tool responses
    â”œâ”€ Rate limiting to prevent excessive API calls
    â””â”€ No PII extraction from parliamentary data
```

### Human Oversight Requirements

```
Human Oversight Workflow:
â”‚
â”œâ”€ Level 1: Automated Checks (CI/CD)
â”‚   â”œâ”€ HTMLHint validation
â”‚   â”œâ”€ axe-core accessibility check
â”‚   â”œâ”€ JSON-LD schema validation
â”‚   â”œâ”€ Hreflang completeness check
â”‚   â””â”€ Bias detection (automated flags)
â”‚
â”œâ”€ Level 2: Peer Review (PR Review)
â”‚   â”œâ”€ Factual accuracy against EP source data
â”‚   â”œâ”€ Political neutrality assessment
â”‚   â”œâ”€ Language quality (native speaker review)
â”‚   â”œâ”€ AI disclosure label present
â”‚   â””â”€ No hallucinated data or statistics
â”‚
â”œâ”€ Level 3: Editorial Oversight
â”‚   â”œâ”€ Cross-article consistency check
â”‚   â”œâ”€ Topic balance across political spectrum
â”‚   â”œâ”€ Sensitive topic escalation
â”‚   â””â”€ Final publication approval
â”‚
â””â”€ Escalation Triggers
    â”œâ”€ Bias flags detected (auto-escalate to Level 2)
    â”œâ”€ Factual discrepancy with EP data (block publication)
    â”œâ”€ Controversial political topic (escalate to Level 3)
    â””â”€ Data unavailable from MCP (flag for manual research)
```

### AI Governance Checklist

| Check | Requirement | Responsible |
|-------|------------|-------------|
| AI disclosure | Label present on all AI-assisted content | news-journalist agent |
| Bias review | Automated bias detection passed | CI/CD pipeline |
| Fact verification | Data matches EP MCP source records | Human reviewer |
| Language quality | Native-level quality in target language | Human reviewer |
| PII protection | No personal data beyond public records | Data pipeline |
| Output sanitization | HTML escaped, no XSS vectors | Frontend validation |
| Agent permissions | Least privilege enforced | security-architect |
| Audit trail | All changes tracked in Git history | Git + GitHub |
| EU AI Act | Transparency obligations met | Editorial team |
| OWASP LLM | Top 10 mitigations applied | security-architect |

## ISMS Compliance Mapping

### ISO 27001:2022
- **A.5.1**: Information security policies â€” AI governance policy documented
- **A.5.8**: Information security in project management â€” AI risk assessment
- **A.5.23**: Cloud service security â€” AI service provider controls
- **A.8.25**: Secure development lifecycle â€” AI code review gates
- **A.8.28**: Secure coding â€” input/output validation for AI pipelines

### NIST CSF 2.0
- **GV.OC-03**: Legal and regulatory requirements (EU AI Act)
- **GV.RM-02**: Risk appetite for AI-generated content defined
- **PR.DS-01**: Data protection for AI-processed parliamentary data
- **DE.CM-01**: Monitoring AI output quality and bias
- **RS.AN-01**: Incident analysis for AI content errors

### CIS Controls v8.1
- **CIS-2**: Software asset inventory â€” AI tools and models tracked
- **CIS-7**: Vulnerability management â€” AI dependency scanning
- **CIS-16**: Application security â€” AI output validation
- **CIS-17**: Incident response â€” AI content error handling

### GDPR
- **Article 5**: Data minimization in AI processing
- **Article 13**: Information provision (AI transparency)
- **Article 22**: Automated decision-making safeguards
- **Article 25**: Data protection by design in AI pipelines
- **Article 35**: DPIA for high-risk AI processing (if applicable)

### EU AI Act
- **Article 50**: Transparency for AI-generated content
- **Article 52**: Obligations for limited-risk AI systems
- **Annex III**: High-risk classification assessment (not applicable)

## Hack23 ISMS Policy References

- [AI Policy](https://github.com/Hack23/ISMS-PUBLIC/blob/main/AI_Policy.md)
- [Information Security Policy](https://github.com/Hack23/ISMS-PUBLIC/blob/main/Information_Security_Policy.md)
- [Secure Development Policy](https://github.com/Hack23/ISMS-PUBLIC/blob/main/Secure_Development_Policy.md)
- [Classification Policy](https://github.com/Hack23/ISMS-PUBLIC/blob/main/Classification_Policy.md)
- [Open Source Policy](https://github.com/Hack23/ISMS-PUBLIC/blob/main/Open_Source_Policy.md)

## References

- [EU AI Act Official Text](https://eur-lex.europa.eu/eli/reg/2024/1689/oj)
- [OWASP LLM Top 10](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
- [NIST AI Risk Management Framework](https://www.nist.gov/artificial-intelligence/ai-risk-management-framework)
- [Hack23 AI Policy](https://github.com/Hack23/ISMS-PUBLIC/blob/main/AI_Policy.md)
- [GitHub Copilot Trust Center](https://resources.github.com/copilot-trust-center/)
- [European Parliament Open Data](https://data.europarl.europa.eu/)
- [EU AI Act Impact Assessment Guide](https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai)
